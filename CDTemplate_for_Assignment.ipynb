{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Defination\n",
    "> Given a sentence that describes the financial situation of a company in the past few years.\n",
    "\n",
    "**Technical routes**\n",
    "+ Methods based on rules\n",
    "+ Methods based on training\n",
    "+ Both above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "> From the sentence as   \n",
    "\"2013年度、2014年度和2015年1-6月，发行人应付账款余额分别为2306万元、635万元和70118万元。\"\n",
    "\n",
    "We extract some entities, include **time**, **attribute**, and **value**.\n",
    "+ **times**:  `2013年度`、`2014年度`、`2015年1-6月`   \n",
    "+ **attributes**: `应收账款`   (attributes might be not complete)  \n",
    "+ **values**: `2306万元`、`635万元`、`70118万元`   \n",
    "\n",
    "> We define a triple is consisted of three ordered components: `[time, attribute, value]`.    \n",
    "If the sentence states that at time `t`, the value of attribute `a` was `v`,      \n",
    "we say triple `[t, a, v]` is a correct triple.\n",
    "\n",
    "All correct triples in current sentence:\n",
    "+ 【2013年度、应付账款、2306万元】  \n",
    "+ 【2014年度、应付账款、635万元】   \n",
    "+ 【2015年1-6月、应付账款、70118万元】  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# ============================================================================\n",
    "#   Copyright (C) 2017 All rights reserved.\n",
    "#\n",
    "#   filename : Assignment_template.py\n",
    "#   author   : chendian / okcd00@qq.com\n",
    "#   date     : 2018-11-15\n",
    "#   desc     : Tensorflow Tuple Extraction Tutorial\n",
    "# ============================================================================\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" (if you want to use GPU2)\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training data and testing data\n",
    "> 使用包含标注信息的训练数据来Train模型参数，\n",
    "> 在测试数据上预测出结果用于打分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据格式\n",
    "\n",
    "**introduction for keys**\n",
    "```python\n",
    "# Every string is Unicode string.\n",
    "{\n",
    "    \"sentenceId\": 'unique id',\n",
    "    \"sentence\": 'A Unicode string',\n",
    "    \"words\": 'A list, that is the result of word segmentation of the sentence',\n",
    "    \"indexes\": 'convert each word in “words” to an index in vocabulary,\\ \n",
    "                notice that all times are converted to the same index,\\ \n",
    "                same as attributes and values',\n",
    "    \"times\": 'which words might representing time',\n",
    "    \"attributes\": 'which words might representing attribute',\n",
    "    \"values\": 'which words might representing value', \n",
    "    \"results\": 'correct triples in this sentence that can be composed by words in “times”, “attributes” and “values”.',\n",
    "}\n",
    "```\n",
    "\n",
    "**Train dataset json file**\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"sentenceId\": \"eadf4c4d7eaa6cb767fa6d8c02555f5-eb85e9fb6ec57b2dd9ba53a8cc4b1625b18\",\n",
    "        \"sentence\": \"2013年度、2014年度、2015年度，公司融资租赁业务收入分别为58,821.17万元、\\\n",
    "                     104,388.84万元和147,579.60万元，分别占发行人营业收入的59.21%、66.59%和66.78%。\",\n",
    "        \"words\": [\n",
    "            \"2013年度\",  \"、\",  \"2014年度\",  \"、\",  \"2015年度\",  \"，\",  \"公司\",  \"融资\",  \"租赁\",  \"业务\",  \"收入\",\n",
    "            \"分别\",  \"为\",  \"58,821.17万元\",  \"、\",  \"104,388.84万元\",  \"和\",  \"147,579.60万元\",  \"，\",  \"分别\", \n",
    "            \"占\",  \"发行\",  \"人\",  \"营业收入\",  \"的\",  \"59.21%\",  \"、\",  \"66.59%\",  \"和\",  \"66.78%\",  \"。\"\n",
    "        ],\n",
    "        \"indexes\": [\n",
    "            0, 6, 0, 6, 0, 7, 13, 104, 146, 33, 1, 11, 8, 2, 6, \n",
    "            2, 9, 2, 7, 11, 14, 17, 18, 1, 12, 2, 6, 2, 9, 2, 10 \n",
    "        ],  \n",
    "        \"times\": [0, 2, 4 ],      # that is [\"2013年度\", \"2014年度\", \"2015年度\"]\n",
    "        \"attributes\": [23, 10 ],  # that is [\"收入\", \"营业收入\"]\n",
    "        \"values\": [13, 15, 17, 25, 27, 29 ], \n",
    "        # that is [\"58,821.17万元\", \"104,388.84万元\", \"147,579.60万元\", \"59.21%\", \"66.59%\", \"66.78%\"]\n",
    "        \"results\": [\n",
    "            [0, 10, 13 ],  # [\"2013年度\", \"收入\", \"58,821.17万元\"]\n",
    "            [2, 10, 15 ],  # [\"2014年度\", \"收入\", \" 104,388.84万元\"]\n",
    "            [4, 10, 17 ]   # [\"2015年度\", \"收入\", \" 147,579.60万元\"]\n",
    "        ], \n",
    "    },\n",
    "    { ... }, \n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Test dataset json file**\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"sentenceId\": \"eadf4c4d7eaa6cb767fa6d8c02555f5-eb85e9fb6ec57b2dd9ba53a8cc4b1625b18\",\n",
    "        \"indexes\": [\n",
    "            0, 6, 0, 6, 0, 7, 13, 104, 146, 33, 1, 11, 8, 2, 6, \n",
    "            2, 9, 2, 7, 11, 14, 17, 18, 1, 12, 2, 6, 2, 9, 2, 10 \n",
    "        ],  \n",
    "        \"times\": [0, 2, 4 ],  \n",
    "        \"attributes\": [23, 10 ],\n",
    "        \"values\": [13, 15, 17, 25, 27, 29 ],\n",
    "    }, \n",
    "    { ... }, \n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Your output json file**\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"sentenceId\": \"eadf4c4d7eaa6cb767fa6d8c02555f5-eb85e9fb6ec57b2dd9ba53a8cc4b1625b18\",\n",
    "        \"results\": [\n",
    "            [0, 10, 13 ],\n",
    "            [4, 10, 17 ], \n",
    "            [2, 10, 15 ]],\n",
    "    },\n",
    "    { ... }, \n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to load training data in Python:\n",
    "import json\n",
    "sentence_list_fname = 'xxx'  # ‘assignment_training_data_word_segment.json’ here\n",
    "sentence_list = json.load(open(sentence_list_fname , ‘r’))\n",
    "\n",
    "# How to load vocabulary in Python:\n",
    "\n",
    "# import pickle (in python 3.x)\n",
    "import cPickle as pickle # (in python 2.x)\n",
    "\n",
    "voc_dict_fname = 'xxx'  # provided file is ‘voc.pkl’ here\n",
    "voc_dict = pickle.load(open(voc_dict_fname, ‘rb’))\n",
    "idx2word, word2idx = voc_dict[‘idx2word’, ‘word2idx’] \n",
    "# idx2word[index] is a word\n",
    "# word2idx[word] is an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network\n",
    "> 定义你自己的网络与计算图，多思考如何构建网络才能让模型参数更好地学到 Triple Matching 的规律。     \n",
    "> **HINT**: 不仅仅是网络，数据的预处理或是后处理也可以纳入考虑的范畴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyNetwork():\n",
    "    def __init__(self, other_params=None):\n",
    "        # Define your placeholders with type, size and name.\n",
    "        \"\"\"\n",
    "        self.X = tf.placeholder(tf.float32, [None, n_features], name='X')\n",
    "        self.y = tf.placeholder(tf.int32, [None, n_classes], name='y')\n",
    "        \"\"\"\n",
    "        self.init_variables(n_features, n_classes)\n",
    "        \n",
    "    def init_variables(self, n_features, n_classes):\n",
    "        # Define your variables\n",
    "        # HINT: or you can directly use existed functions.\n",
    "        \"\"\"\n",
    "        self.W = tf.Variable(\n",
    "            initial_value=tf.constant(0.0, shape=[n_features, n_classes]),\n",
    "            dtype=tf.float32, name='weight')\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=tf.constant(0.0, shape=[n_classes]),\n",
    "            dtype=tf.float32, name='bias')\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def sigmoid(self, logits):\n",
    "        return tf.nn.sigmoid(hidden)\n",
    "    \n",
    "    def softmax(self, logits):\n",
    "        # softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "        return tf.nn.softmax(logits, -1)\n",
    "    \n",
    "    def prob_layer(self, hidden, mask=None, expand_dim=False):\n",
    "        # calculate probability from hidden\n",
    "        prob = self.sigmoid(hidden) * mask\n",
    "        if expand_dim:\n",
    "            # twins_prob = tf.concat([prob, 1.0 - prob], -1)\n",
    "            return tf.expand_dims(prob, -1)\n",
    "        return prob\n",
    "    \n",
    "    def get_network(self):\n",
    "        # hidden = how_to_get_my_hidden_value()\n",
    "        # probs = self.prob_layer(hidden)\n",
    "        # self.y_pred = how_to_get_predict_value(probs)\n",
    "        # return self.y_pred, hidden\n",
    "        pass\n",
    "    \n",
    "    def get_loss(self, hidden):\n",
    "        self.loss = 0.0\n",
    "        # my_loss_function = ...\n",
    "        # labels, logits = ..., ...\n",
    "        # self.loss = my_loss_function(labels, logits)\n",
    "        return tf.reduce_mean(self.loss)\n",
    "    \n",
    "    def generate_feed_dict(self, data):\n",
    "        feed_dict = {}\n",
    "        # feed_dict[self.X] = data['data_x']\n",
    "        # feed_dict[self.y] = data['data_y']\n",
    "        return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer\n",
    "> 因为深度学习常见的是对于梯度的优化，也就是说，     \n",
    "> 优化器最后其实就是各种对于梯度下降算法的优化。\n",
    "\n",
    "常见的优化器有 SGD，RMSprop，Adagrad，Adadelta，Adam 等，      \n",
    "下面给出各个Optimizer的初始化示例以供选择，   \n",
    "此处实例中默认使用的是 Adam（也是目前最为广泛使用的一个），    \n",
    "大多数机器学习的任务就是最小化Loss，在定义好Loss的情况下，后面的工作就交给优化器处理即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(learning_rate, optim=None):\n",
    "    # get optimizer for training, AdamOptimizer as default\n",
    "    optim = self.options.get('optimizer', 'N/A')\n",
    "    if optim == 'sgd':\n",
    "        return tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    elif optim == 'rmsprop':\n",
    "        return tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "    elif optim == 'adadelta':\n",
    "        return tf.train.AdadeltaOptimizer()\n",
    "    else:  # if optim == 'adam':\n",
    "        return tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    self.sess = tf.Session()\n",
    "    self.network = MyNetwork()  # Classifier\n",
    "    self.train_output = self.get_model_train()  # y_pred, loss\n",
    "    self.test_output = self.get_model_test()  # y_pred\n",
    "    \n",
    "    self.optimizer = get_optimizer(learning_rate, 'adam').minimize(self.train_output[-1])\n",
    "    self.sess.run(tf.global_variables_initializer())\n",
    "    self.init_saver()\n",
    "    \n",
    "    def errors(self, y_pred, y_truth=None):\n",
    "        err = 0.0\n",
    "        # err = calculate_errors(y_pred, y_truth)\n",
    "        return err\n",
    "    \n",
    "    def get_model_train(self):\n",
    "        with tf.name_scope('train'):\n",
    "            y_pred, hidden = self.network.get_network()\n",
    "            loss = self.network.get_loss(hidden)\n",
    "            return y_pred, loss\n",
    "    \n",
    "    def get_model_test(self):\n",
    "        with tf.name_scope('test'):\n",
    "            y_pred, hidden = self.network.get_network()\n",
    "            return y_pred\n",
    "    \n",
    "    def init_saver(self, var_list=None):\n",
    "        if self.saver is not None:\n",
    "            return\n",
    "        self.saver = tf.train.Saver(\n",
    "            var_list = tf.global_variables(),\n",
    "            reshape=True,\n",
    "            sharded=False,\n",
    "            restore_sequentially=True,\n",
    "            write_version=tf.train.SaverDef.V2)\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        if self.saver is None:\n",
    "            self.init_saver()\n",
    "        # save session in file\n",
    "        self.saver.save(self.sess, save_path=path)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        if self.saver is None:\n",
    "            self.init_saver()\n",
    "        self.saver.restore(self.session, path)\n",
    "    \n",
    "    def call_model(self, data, mode='train'):\n",
    "        # generate data for placeholder\n",
    "        if mode == 'test':\n",
    "            ret = self.sess.run(  # return y_pred\n",
    "                test_output,\n",
    "                feed_dict=self.network.gen_input(data))\n",
    "        else:  # mode == 'train'\n",
    "            _, ret = self.sess.run(  # return y_pred, loss\n",
    "                [optimizer, train_output], \n",
    "                feed_dict=self.network.gen_input(data))\n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something about training and cross validation\n",
    "When you want to evaluate your model and choose hyper-parameters,   \n",
    "**cross validation**(CV) is usually useful.  \n",
    "\n",
    "**K-fold CV**:  \n",
    "Split all data you have into k folds.   \n",
    "If you set a hyper-parameter, to evaluate your model, you should do something like this:  \n",
    "```python\n",
    "for i in range(k):  \n",
    "    model = # train on all folds except the ith fold.  \n",
    "    errors[i] = # model prediction error on the ith fold (use measures like F1, precision, cost)  \n",
    "error = mean(errors)  \n",
    "```\n",
    "And you can try many hyper-parameter settings and choose the best one.  \n",
    "\n",
    "\n",
    "## Start Training\n",
    "> 对于各自的模型，选择与处理输入数据（data），设置参数，交由模型进行训练    \n",
    "> 保存效果最好的模型参数，确认可以正确的进行读取与预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # call model class for a instance\n",
    "    model = MyModel()\n",
    "\n",
    "    # train_set_x, train_set_y, test_set_x,  test_set_y = ...\n",
    "    # HINT: X-Fold Cross Validation.\n",
    "\n",
    "    epoch = 0\n",
    "    print(\"Now training.\")\n",
    "    while epoch < n_epochs:\n",
    "        # draw a figure every 'draw_freq' times\n",
    "\n",
    "        # print error/cost per epoch\n",
    "        train_pred, loss = model.call_model(\n",
    "            train_set_x, train_set_y, 'train')\n",
    "        train_error = model.errors(\n",
    "            y_pred=train_pred, y_truth=train_set_y)\n",
    "\n",
    "        test_pred = model.call_model(\n",
    "            test_set_x,  test_set_y, 'test')\n",
    "        test_error = model.errors(\n",
    "            y_pred=test_pred, y_truth=test_set_y)\n",
    "\n",
    "        print (\"epoch is %d, train error %f, test error %f\" % (\n",
    "            epoch, train_error, test_error))\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Checking\n",
    "> Source Code 选自2017年人工智能基础课 **韩柔刚** 同学，     \n",
    "作简要格式修改后放在这里，便于各位同学测试自己模型效果使用，   \n",
    "便于测试或用于为不擅长写error计算函数的同学作简要替代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "\n",
    "info = json.load(open(\"data.json\", 'r'))  # original data json\n",
    "answers = json.load(open(\"output.json\", 'r'))  # your prediction\n",
    "\n",
    "n_info = len(info)\n",
    "n_answers = len(answers)\n",
    "\n",
    "prec, recall = 0., 0.\n",
    "post, negt, posf = 0, 0, 0\n",
    "\n",
    "n = n_answers\n",
    "\n",
    "if n_info == n_answers:\n",
    "    print (\"No missing or flowing problem\")\n",
    "else:\n",
    "    if n_info < n_answers:\n",
    "        n = n_info\n",
    "        print (\"flowing problems\")\n",
    "    else :\n",
    "        n = n_answers\n",
    "        print (\"missing problems\")\n",
    "\n",
    "for i in numpy.arange(0, n):\n",
    "    for r in info[i][\"results\"]:\n",
    "        if (r in answers[i][\"results\"]):\n",
    "            post = post + 1\n",
    "        else :\n",
    "            posf = posf + 1\n",
    "    for r in answers[i][\"results\"]:\n",
    "        if (r not in info[i][\"results\"]):\n",
    "            negt = negt + 1\n",
    "\n",
    "recall = post * 1. / (post + posf)\n",
    "prec   = post * 1. / (post + negt)\n",
    "correct = post * 1. / (post + posf + negt)\n",
    "f1 = (prec * recall) * 2. / (prec + recall)\n",
    "\n",
    "print(\"recall:%.2lf prec:%.2lf correct:%.2lf F1:%.2lf\" % (recall, prec, correct, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-learning material\n",
    "+ **Python** @ COGS18\n",
    "  + Introduction to Python (COGS18) is a course offered by the Department of Cognitive Science of UC San Diego, taught by Tom Donoghue. It is a hands-on programming course, focused on teaching students in Cognitive Science and related disciplines an introduction on how to productively use Python.\n",
    "  + https://cogs18.github.io/intro/\n",
    "+ **More Python Packages** @ 机器之心\n",
    "  + Python 成功和受欢迎的原因之一是存在强大的库，这些库使 Python 极具创造力且运行快速。然而，使用 Pandas、Scikit-learn、Matplotlib 等常见库在解决一些特殊的数据问题时可能并不实用，本文介绍的这些非常见库可能更有帮助。\n",
    "  + https://mp.weixin.qq.com/s/cLCfdaCMub0xEtbgv4b-cQ\n",
    "+ **Tensorflow** @ Google\n",
    "  + TensorFlow 最近提供了官方中文版教程（Tutorials）和中文版指南（Guide）。其中教程主要介绍了 TensorFlow 的基本概念，以及各种基础模型的简单实现方法，这些模型基本上都是用 Keras 等易于理解的高阶 API 完成。而指南则深入介绍了 TensorFlow 的工作原理，包括高阶 API、Estimator、低阶 API 和 TensorBoard 等。 ——by 机器之心\n",
    "  + https://tensorflow.google.cn/tutorials/?hl=zh-cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42, 27, 41, 13, 46, 47, 23, 10, 17, 19, 37, 45, 31, 26, 36, 12,  2,\n",
       "       32, 43, 48,  5, 18, 21,  4, 22, 40, 25, 39, 33,  1, 49, 28, 38,  3,\n",
       "       15,  6, 24, 14, 35,  7, 16, 11, 34, 29,  9, 50,  8, 30, 44, 20])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# for random groups generating\n",
    "a = np.arange(1, 51)\n",
    "np.random.shuffle(a)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (tf.1.10)",
   "language": "python",
   "name": "tensorflow1.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
